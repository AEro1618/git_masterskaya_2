# Мастерская №2 
## Описание проекта
Интернет-магазин собирает историю покупателей, проводит рассылки предложений и планирует будущие продажи. 
Для оптимизации процессов надо выделить пользователей, которые готовы совершить покупку в ближайшее время.
Вам предстоит выполнить инженеринг признаков, обучить и оптимизировать модель бинарной классификации, которая предскажет вероятность совершения покупки пользователем в течение 90 дней.

Цель: Предсказать вероятность покупки в течение 90 дней

### Результат проекта
Репозиторий на гитхабе:
1. Тетрадь jupyter notebook с описанием, подготовкой признаков, обучением модели и
тестированием
2. Описание проекта и инструкция по использованию в файле README.md
3. Список зависимостей в файле requirements.txt

### План проекта:
1. Изучить данные
2. Разработать полезные признаки
3. Создать модель для классификации пользователей
4. Улучшить модель и максимизировать метрику roc_auc
5. Выполнить тестирование

### Описание данных:
apparel-purchases история покупок
- Данные о покупках клиентов по дням и по товарам. 
- В каждой записи покупка определенного товара, его цена, количество штук.
- В таблице есть списки идентификаторов, к каким категориям относится товар. Часто это вложенные категории (например автотовары-аксессуары-освежители), но также может включать в начале списка маркер распродажи или маркер женщинам/мужчинам.
- Нумерация категорий сквозная для всех уровней, то есть 44 на второй позиции списка или на третьей – это одна и та же категория. 
- Иногда дерево категорий обновляется, поэтому могут меняться вложенности, например ['4', '28', '44', '1594'] или ['4', '44', '1594']. Как обработать такие случаи – можете предлагать свои варианты решения.


- client_id - идентификатор пользователя
- quantity - количество товаров в заказе
- price цена - товара
- category_ids - вложенные категории, к которым отнсится товар
- date - дата покупки
- message_id - идентификатор сообщения из рассылки

apparel-messages история рекламных рассылок
Рассылки, которые были отправлены клиентам из таблицы покупок.
- bulk_campaign_id - идентификатор рекламной кампании
- client_id - идентификатор пользователя
- message_id - идентификатор сообщений
- event тип - действия
- channel - канал рассылки
- date - дата рассылки
- created_at - точное время создания сообщения


apparel-target_binary
совершит ли клиент покупку в течение следующих 90 дней
- client_id идентификатор пользователя
- target целевой признак

Общая база рассылок огромна, поэтому собрали для вас агрегированную по дням статистику по рассылкам. Если будете создавать на основе этой статистики дополнительные признаки, обратите внимание, что нельзя суммировать по колонкам nunique, потому что это уникальные клиенты в пределах дня, у вас нет данных, повторяются ли они в другие дни

full_campaign_daily_event - Агрегация общей базы рассылок по дням и типам событий
- date - дата
- bulk_campaign_id - идентификатор рассылки
- count_event - общее количество каждого события event количество уникальных client_id в каждом событии
- nunique_event - в именах колонок найдете все типы событий event

full_campaign_daily_event_channel Агрегация по дням с учетом событий и каналов рассылки
- date - дата
- bulk_campaign_id - идентификатор рассылки
- count_event_channel - общее количество каждого события по каналам количество уникальных client_id по событиям и каналам
- nunique_event_channel - в именах колонок есть все типы событий event и каналов рассылки channel

## Структура кода в проекте:

Код организован как последовательность независимых функций, вызываемых в `main()`:

```python
def main():
    # 1. Загрузка
    df_target, df_messages, ... = load_data()
    
    # 2. Предобработка
    result_df = preprocess_data(df_target, df_messages, ...)
    
    # 3. Анализ
    result_df = enhanced_eda(result_df)
    
    # 4. Моделирование
    final_model = train_final_model(result_df)
    
    # 5. Оценка
    test_results = test_model(final_model, result_df)
    
    # 6. Сохранение
    final_model.save_model('final_model.cbm')
```
## Перечень и описание этапов реализации проекта

### 1. Этап загрузки данных (`load_data()`)

- Реализован отдельной функцией

### 1. Этап предобработки (`preprocess_data()`)

Сложная многошаговая обработка вынесена в отдельную функцию:
- Объединяет данные из разных источников
- Выполняет критически важные преобразования:
  - Обработка временных меток
  - Агрегация покупок и сообщений
  - Создание объединенного датафрейма
- Реализует логику обработки категорий

### 2. Исследовательский анализ данных (`eda()`)

Выполняет комплексный анализ потому что:
- Дает понимание распределения целевой переменной
- Выявляет важные закономерности в данных
- Помогает обнаружить проблемы с данными
- Формирует гипотезы для feature engineering

### 3. Конструирование признаков

Отдельные функции (`add_time_features()`, `add_rfm_features()`, `add_behavior_features()`) 
- Позволяют легко добавлять новые группы признаков
- Позволяют тестировать группы признаков независимо

### 4. Обучение модели (`train_final_model()`)

Процесс обучения вынесен в отдельную функцию:
- Включает логику кросс-валидации
- Работу с дисбалансом SMOTE
- Оптимизацию признакового пространства
- Включает комплексную оценку качества

### 5. Тестирование модели (`test_model()`)
- Отложенная выборка
- Оценка качества модели

## Техники использованные в проекте

1. **Временная кросс-валидация**:
   - Используется TimeSeriesSplit вместо случайных разбиений
   - Сохраняется временная зависимость в данных
   - Более реалистичная оценка производительности

2. **Борьба с дисбалансом**:
   - Применен SMOTE для синтетической генерации примеров
   - Использован scale_pos_weight в CatBoost

3. **Оптимизация признаков**:
   - Удаление неинформативных признаков
   - Фильтрация сильно коррелирующих признаков

4. **Оценка модели**:
   - Используются ROC-AUC и PR-кривые
   - Оценивается стабильность по фолдам